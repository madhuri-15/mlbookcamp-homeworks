{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9445ae2",
   "metadata": {},
   "source": [
    "## Deep Learning - Homework Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d84b2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 07:22:30.835606: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "# Import libaries\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# for images\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ade5899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 07:22:36.870498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 07:22:36.876844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 07:22:36.877457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 07:22:36.878438: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-23 07:22:36.878810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 07:22:36.879447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 07:22:36.880013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 07:22:37.532460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 07:22:37.533200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 07:22:37.533761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 07:22:37.534290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13795 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Creating a model from scratch\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Add a input\n",
    "model.add(keras.Input(shape=(150, 150, 3)))\n",
    "\n",
    "# Create a convolutional layer\n",
    "model.add(keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# Reduced the size of feature map with max pooling(MaxPooling2D)\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add flatten layer to convert multi-dimensional results into vectors\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "# Add a dense layer with 64 nuerons\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "\n",
    "# Add a output dense layer with 1 nueron\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Model training\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.002, momentum=0.8)\n",
    "loss = keras.losses.BinaryCrossentropy()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10d46654",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Q2. What's the total number of parameters of the model? ANSWER- 11215873\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff21ca41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 2 classes.\n",
      "Found 394 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "img_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Read from directory\n",
    "train_df = img_gen.flow_from_directory(\"./train\",\n",
    "                                       class_mode='binary',\n",
    "                                       target_size=(150, 150),\n",
    "                                       batch_size=20,\n",
    "                                       shuffle=True)\n",
    "\n",
    "# For validation data\n",
    "test_df = img_gen.flow_from_directory(\"./test\",\n",
    "                                      class_mode='binary',\n",
    "                                      target_size=(150, 150),\n",
    "                                      batch_size=20,\n",
    "                                      shuffle=False\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5ac5486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 07:22:39.873122: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-11-23 07:22:40.511049: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-23 07:22:40.512077: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-23 07:22:40.512113: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-11-23 07:22:40.513168: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-23 07:22:40.513264: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 12s 121ms/step - loss: 0.5976 - accuracy: 0.6706 - val_loss: 0.4914 - val_accuracy: 0.7817\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.4565 - accuracy: 0.8105 - val_loss: 0.4093 - val_accuracy: 0.8249\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.3888 - accuracy: 0.8338 - val_loss: 0.3597 - val_accuracy: 0.8503\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.3285 - accuracy: 0.8689 - val_loss: 0.4866 - val_accuracy: 0.7690\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.2993 - accuracy: 0.8877 - val_loss: 0.3910 - val_accuracy: 0.8223\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.2733 - accuracy: 0.8952 - val_loss: 0.3393 - val_accuracy: 0.8401\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.2370 - accuracy: 0.9172 - val_loss: 0.3031 - val_accuracy: 0.8528\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.2168 - accuracy: 0.9191 - val_loss: 0.2871 - val_accuracy: 0.8680\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.1960 - accuracy: 0.9297 - val_loss: 0.3212 - val_accuracy: 0.8604\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.1748 - accuracy: 0.9417 - val_loss: 0.2736 - val_accuracy: 0.8807\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "model_hist = model.fit(\n",
    "    train_df,\n",
    "    epochs=10,\n",
    "    validation_data=test_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af2b8e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c1a4599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3. Median of training accuracy:: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Q3.What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "median_train_acc = np.median(history['accuracy'])\n",
    "print(\"Q3. Median of training accuracy:: %.2f\" % median_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a109d74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4. Standard deviation of training loss:: 0.13\n"
     ]
    }
   ],
   "source": [
    "# Q4.What is the standard deviation of training loss for all the epochs for this model?\n",
    "std_loss = np.std(history['loss'])\n",
    "print(\"Q4. Standard deviation of training loss:: %.2f\" %std_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ec25108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 2 classes.\n",
      "Found 394 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Agumentation\n",
    "train_gen = ImageDataGenerator(rescale=1./255,\n",
    "                               rotation_range=40,\n",
    "                               width_shift_range=0.2,\n",
    "                               height_shift_range=0.2,\n",
    "                               shear_range=0.2,\n",
    "                               zoom_range=0.2,\n",
    "                               horizontal_flip=True,\n",
    "                               fill_mode='nearest'\n",
    "                              )\n",
    "\n",
    "# Read from directory\n",
    "train_df = train_gen.flow_from_directory(\"./train\",\n",
    "                                       class_mode='binary',\n",
    "                                       target_size=(150, 150),\n",
    "                                       batch_size=20,\n",
    "                                       shuffle=True)\n",
    "\n",
    "# For test data\n",
    "img_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_df = img_gen.flow_from_directory(\"./test\",\n",
    "                                      class_mode='binary',\n",
    "                                      target_size=(150, 150),\n",
    "                                      batch_size=20,\n",
    "                                      shuffle=False\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2066d27c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "80/80 [==============================] - 15s 188ms/step - loss: 0.4494 - accuracy: 0.7949 - val_loss: 0.3641 - val_accuracy: 0.8350\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 15s 186ms/step - loss: 0.4387 - accuracy: 0.7949 - val_loss: 0.4714 - val_accuracy: 0.7741\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 15s 189ms/step - loss: 0.4230 - accuracy: 0.8030 - val_loss: 0.3139 - val_accuracy: 0.8604\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 15s 188ms/step - loss: 0.3959 - accuracy: 0.8243 - val_loss: 0.6701 - val_accuracy: 0.7183\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 15s 187ms/step - loss: 0.3928 - accuracy: 0.8407 - val_loss: 0.4512 - val_accuracy: 0.7995\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 15s 186ms/step - loss: 0.3752 - accuracy: 0.8319 - val_loss: 0.3350 - val_accuracy: 0.8401\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 15s 186ms/step - loss: 0.3856 - accuracy: 0.8294 - val_loss: 0.2608 - val_accuracy: 0.8782\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 15s 187ms/step - loss: 0.3682 - accuracy: 0.8350 - val_loss: 0.5767 - val_accuracy: 0.7487\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 15s 186ms/step - loss: 0.3600 - accuracy: 0.8394 - val_loss: 0.3922 - val_accuracy: 0.8249\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 15s 186ms/step - loss: 0.3623 - accuracy: 0.8425 - val_loss: 0.3664 - val_accuracy: 0.8376\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 15s 186ms/step - loss: 0.3431 - accuracy: 0.8457 - val_loss: 0.4214 - val_accuracy: 0.8071\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 15s 187ms/step - loss: 0.3313 - accuracy: 0.8595 - val_loss: 0.2959 - val_accuracy: 0.8706\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 15s 187ms/step - loss: 0.3448 - accuracy: 0.8557 - val_loss: 0.2693 - val_accuracy: 0.8756\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 15s 186ms/step - loss: 0.3318 - accuracy: 0.8651 - val_loss: 0.3937 - val_accuracy: 0.8325\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 15s 185ms/step - loss: 0.3207 - accuracy: 0.8570 - val_loss: 0.3153 - val_accuracy: 0.8553\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 15s 187ms/step - loss: 0.3248 - accuracy: 0.8689 - val_loss: 0.3842 - val_accuracy: 0.8426\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 15s 186ms/step - loss: 0.3212 - accuracy: 0.8683 - val_loss: 0.4017 - val_accuracy: 0.8376\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 15s 185ms/step - loss: 0.3147 - accuracy: 0.8745 - val_loss: 0.5168 - val_accuracy: 0.8046\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 15s 186ms/step - loss: 0.2983 - accuracy: 0.8839 - val_loss: 0.3965 - val_accuracy: 0.8426\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 15s 187ms/step - loss: 0.3107 - accuracy: 0.8758 - val_loss: 0.5299 - val_accuracy: 0.7843\n"
     ]
    }
   ],
   "source": [
    "# model training with agumentated data\n",
    "model_hist = model.fit(\n",
    "    train_df,\n",
    "    epochs=20,\n",
    "    validation_data=test_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "648c3a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d45dfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5. Mean of test loss for all the epochs:: 0.41\n"
     ]
    }
   ],
   "source": [
    "# Q5.What is the mean of test loss for all the epochs for the model trained with augmentations?\n",
    "avg_loss_test = np.mean(history['val_loss'])\n",
    "print(\"Q5. Mean of test loss for all the epochs:: %.2f\" % avg_loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fd0fc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q6. Mean of test loss for all the epochs:: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Q6.What's the average of test accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?\n",
    "avg_test_acc = np.mean(history['val_accuracy'][-5:])\n",
    "print(\"Q6. Mean of test loss for all the epochs:: %.2f\" % avg_test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
